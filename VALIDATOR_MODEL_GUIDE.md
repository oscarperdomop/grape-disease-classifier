# ðŸ” Validator Model Guide

## Â¿QuÃ© es el Validator?

Un **modelo binario** que valida si una imagen es una **hoja de uva** antes de procesarla con los clasificadores de enfermedad.

### Flujo de PredicciÃ³n

```
1. Usuario sube imagen
   â†“
2. VALIDATOR MODEL â†’ Â¿Es hoja de uva?
   â”œâ”€ SÃ â†’ Continuar a clasificadores de enfermedad
   â””â”€ NO â†’ Retornar error "Image is not in scope"
   â†“
3. Cargar modelo de enfermedad (model_1, model_2, model_3, model_4)
   â†“
4. Clasificar enfermedad
   â†“
5. Retornar resultados
```

---

## ðŸŽ¯ Objetivo del Validator

Rechazar imÃ¡genes que **NO sean hojas de uva**:

- âŒ Fotos de carros
- âŒ Fotos de personas
- âŒ Fotos de edificios
- âŒ Fotos de otras plantas
- âŒ ImÃ¡genes genÃ©ricas

Aceptar imÃ¡genes que **SÃ sean hojas de uva**:

- âœ… Hojas sanas
- âœ… Hojas con enfermedades
- âœ… Hojas parciales
- âœ… Hojas en diferentes Ã¡ngulos

---

## ðŸ“Š Estructura del Modelo

### Entrada
- **Imagen**: 224x224 pÃ­xeles (RGB)
- **NormalizaciÃ³n**: ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

### Salida
- **Clase 0**: "No es hoja de uva" (probabilidad)
- **Clase 1**: "Es hoja de uva" (probabilidad)

### Threshold
- **Default**: 0.5 (50% confianza)
- **Configurable**: `VALIDATOR_MODEL_THRESHOLD` en `app.py`

---

## ðŸ—ï¸ CÃ³mo Entrenar el Validator

### OpciÃ³n 1: Usar Modelo Pre-entrenado (Recomendado)

Si ya tienes un modelo binario ONNX:

1. Crea carpeta: `models/validator/`
2. Coloca el modelo: `models/validator/model.onnx`
3. (Opcional) Agrega config: `models/validator/config.json`

```json
{
  "labels": ["Not Grape Leaf", "Grape Leaf"],
  "classes": ["Not Grape Leaf", "Grape Leaf"]
}
```

### OpciÃ³n 2: Entrenar desde Cero

#### Paso 1: Preparar Dataset

```
dataset/
â”œâ”€â”€ grape_leaf/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ... (100-500 imÃ¡genes de hojas de uva)
â””â”€â”€ not_grape_leaf/
    â”œâ”€â”€ car1.jpg
    â”œâ”€â”€ person1.jpg
    â”œâ”€â”€ building1.jpg
    â””â”€â”€ ... (100-500 imÃ¡genes de otras cosas)
```

#### Paso 2: Script de Entrenamiento

```python
import torch
import torch.nn as nn
from torchvision import models, transforms
from torch.utils.data import DataLoader, ImageFolder
import onnx
import onnxruntime

# ConfiguraciÃ³n
BATCH_SIZE = 32
EPOCHS = 10
LEARNING_RATE = 0.001

# Dataset
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

train_dataset = ImageFolder('dataset', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

# Modelo
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(512, 2)  # Binary classification
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# Entrenamiento
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

for epoch in range(EPOCHS):
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    print(f"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.4f}")

# Exportar a ONNX
dummy_input = torch.randn(1, 3, 224, 224).to(device)
torch.onnx.export(
    model,
    dummy_input,
    'models/validator/model.onnx',
    input_names=['input'],
    output_names=['output'],
    opset_version=12
)

print("âœ… Modelo exportado a models/validator/model.onnx")
```

#### Paso 3: Validar Modelo ONNX

```python
import onnxruntime as ort
import numpy as np
from PIL import Image

# Cargar modelo
sess = ort.InferenceSession('models/validator/model.onnx')

# Cargar imagen de prueba
img = Image.open('test_image.jpg').resize((224, 224))
arr = np.array(img).astype(np.float32) / 255.0

# Normalizar
mean = np.array([0.485, 0.456, 0.406])
std = np.array([0.229, 0.224, 0.225])
arr = (arr - mean) / std
arr = np.transpose(arr, (2, 0, 1))
arr = np.expand_dims(arr, axis=0)

# PredicciÃ³n
input_name = sess.get_inputs()[0].name
output = sess.run(None, {input_name: arr})[0]
probs = np.exp(output) / np.sum(np.exp(output), axis=1, keepdims=True)

print(f"No es hoja de uva: {probs[0][0]:.2%}")
print(f"Es hoja de uva: {probs[0][1]:.2%}")
```

---

## ðŸ”§ ConfiguraciÃ³n en app.py

### Ajustar Threshold

```python
# En app.py, lÃ­nea ~56
VALIDATOR_MODEL_THRESHOLD = 0.5  # Cambiar segÃºn necesidad

# Valores recomendados:
# 0.3 - MÃ¡s permisivo (acepta mÃ¡s imÃ¡genes)
# 0.5 - Balanceado (default)
# 0.7 - MÃ¡s estricto (rechaza mÃ¡s imÃ¡genes)
```

### Deshabilitar Validator (Opcional)

Si no tienes modelo validador, el sistema funciona sin Ã©l:

```python
# El validator simplemente no se carga
# y todas las imÃ¡genes se aceptan
```

---

## ðŸ“ Respuestas del API

### Imagen VÃ¡lida (Hoja de Uva)

```json
{
  "predictions": [
    {
      "label": "Healthy",
      "index": 0,
      "score": 0.95
    }
  ]
}
```

### Imagen InvÃ¡lida (No es Hoja de Uva)

```json
{
  "error": "Image is not in scope",
  "message": "The image does not appear to be a grape leaf",
  "validation_confidence": 0.23,
  "note": "Please provide an image of a grape leaf for analysis"
}
```

---

## ðŸ“Š MÃ©tricas Recomendadas

Para evaluar el validator:

```python
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support

# DespuÃ©s de predicciones en test set
tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()

# MÃ©tricas
accuracy = (tp + tn) / (tp + tn + fp + fn)
precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1 = 2 * (precision * recall) / (precision + recall)

print(f"Accuracy: {accuracy:.2%}")
print(f"Precision: {precision:.2%}")
print(f"Recall: {recall:.2%}")
print(f"F1-Score: {f1:.2%}")

# Objetivo: Accuracy > 95%, Recall > 90%
```

---

## ðŸš€ Deployment

### 1. Entrenar Modelo Localmente

```bash
python train_validator.py
```

### 2. Crear Release en GitHub

```bash
# Crear carpeta con modelo
mkdir -p models/validator
cp model.onnx models/validator/
cp config.json models/validator/

# Commit
git add models/validator/
git commit -m "Add validator model"
git push origin main

# Crear release con archivo ZIP
# En GitHub: Releases â†’ Create Release â†’ Upload models.zip
```

### 3. Render DescargarÃ¡ AutomÃ¡ticamente

El script `download_models.py` descargarÃ¡ el validator junto con otros modelos.

---

## âœ… Testing

### Endpoint de Info

```bash
curl https://your-api.com/validator
```

Respuesta:
```json
{
  "validator_enabled": true,
  "validator_model_id": "validator",
  "validator_threshold": 0.5,
  "description": "Binary classifier that validates if image is a grape leaf",
  "usage": "Automatically runs before disease classification"
}
```

### Probar con Imagen VÃ¡lida

```bash
curl -X POST -F "file=@grape_leaf.jpg" \
  https://your-api.com/predict?model_id=model_1
```

### Probar con Imagen InvÃ¡lida

```bash
curl -X POST -F "file=@car.jpg" \
  https://your-api.com/predict?model_id=model_1
```

DeberÃ­a retornar:
```json
{
  "error": "Image is not in scope",
  "message": "The image does not appear to be a grape leaf",
  "validation_confidence": 0.15
}
```

---

## ðŸ“š Referencias

- [PyTorch ONNX Export](https://pytorch.org/docs/stable/onnx.html)
- [ONNX Runtime Python](https://onnxruntime.ai/docs/get-started/with-python.html)
- [ImageNet Normalization](https://pytorch.org/vision/stable/models.html)
